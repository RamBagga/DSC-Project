{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41760d42",
   "metadata": {},
   "source": [
    "# *DSC Recruitment Task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebaa2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029cf1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel(r\"C:\\Users\\priya\\OneDrive\\Desktop\\Training Data.xlsx\",nrows=10000)  # inputting the data file\n",
    "data = data.reindex(np.random.permutation(data.index))     # shuffle the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69706988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003889</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>-0.006409</td>\n",
       "      <td>-0.011190</td>\n",
       "      <td>-0.010928</td>\n",
       "      <td>-0.054972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.003889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009102</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>-0.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.009843</td>\n",
       "      <td>-0.009102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>-0.014829</td>\n",
       "      <td>-0.029871</td>\n",
       "      <td>-0.010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>-0.006409</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642051</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>-0.014410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_job_years</th>\n",
       "      <td>-0.011190</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>-0.014829</td>\n",
       "      <td>0.642051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.013292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_house_years</th>\n",
       "      <td>-0.010928</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>-0.029871</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk_flag</th>\n",
       "      <td>-0.054972</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.010264</td>\n",
       "      <td>-0.014410</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Id    income       age  experience  \\\n",
       "Id                   1.000000 -0.003889 -0.009843   -0.006409   \n",
       "income              -0.003889  1.000000 -0.009102    0.007608   \n",
       "age                 -0.009843 -0.009102  1.000000   -0.010909   \n",
       "experience          -0.006409  0.007608 -0.010909    1.000000   \n",
       "current_job_years   -0.011190  0.009788 -0.014829    0.642051   \n",
       "current_house_years -0.010928 -0.011321 -0.029871    0.022246   \n",
       "risk_flag           -0.054972 -0.001195 -0.010264   -0.014410   \n",
       "\n",
       "                     current_job_years  current_house_years  risk_flag  \n",
       "Id                           -0.011190            -0.010928  -0.054972  \n",
       "income                        0.009788            -0.011321  -0.001195  \n",
       "age                          -0.014829            -0.029871  -0.010264  \n",
       "experience                    0.642051             0.022246  -0.014410  \n",
       "current_job_years             1.000000             0.008985   0.013292  \n",
       "current_house_years           0.008985             1.000000  -0.003068  \n",
       "risk_flag                     0.013292            -0.003068   1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=data.sample(frac=0.80)\n",
    "test_data=data.drop(training_data.index)\n",
    "##creating training and test data from the original data frame with a ratio of 80:20\n",
    "training_data.corr()\n",
    "\n",
    "##trying to find relations between features and target variable risk_flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926b31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df_mean = training_data.loc[:,training_data.columns!=\"risk_flag\"].mean()\n",
    "train_df_std = training_data.loc[:,training_data.columns!=\"risk_flag\"].std()\n",
    "train_df_mean[\"risk_flag\"]=0\n",
    "train_df_std[\"risk_flag\"]=1\n",
    "train_df_norm = (training_data - train_df_mean)/train_df_std\n",
    "##scaling all the features to similar values\n",
    "test_df_mean = test_data.loc[:,test_data.columns!=\"risk_flag\"].mean()\n",
    "test_df_std  = test_data.loc[:,test_data.columns!=\"risk_flag\"].std()\n",
    "test_df_mean[\"risk_flag\"]=0\n",
    "test_df_std[\"risk_flag\"]=1\n",
    "test_df_norm = (test_data - test_df_mean)/test_df_std\n",
    "##Scaling test data too\n",
    "feature_columns=[]\n",
    "##A empty list to contain all feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79117215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del train_df_norm[\"car_ownership\"]\n",
    "del train_df_norm[\"city\"]\n",
    "del train_df_norm[\"house_ownership\"]\n",
    "del train_df_norm[\"married\"]\n",
    "del train_df_norm[\"profession\"]\n",
    "del train_df_norm[\"state\"]\n",
    "\n",
    "del test_df_norm[\"car_ownership\"]\n",
    "del test_df_norm[\"city\"]\n",
    "del test_df_norm[\"house_ownership\"]\n",
    "del test_df_norm[\"married\"]\n",
    "del test_df_norm[\"profession\"]\n",
    "del test_df_norm[\"state\"]\n",
    "\n",
    "##deleting unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94119c35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>experience</th>\n",
       "      <th>income</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-1.576452</td>\n",
       "      <td>-0.888100</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.373224</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>1.240050</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>-1.415761</td>\n",
       "      <td>1.634994</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.099022</td>\n",
       "      <td>0.644336</td>\n",
       "      <td>-0.997847</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>-1.295590</td>\n",
       "      <td>1.693671</td>\n",
       "      <td>-1.439179</td>\n",
       "      <td>-0.373224</td>\n",
       "      <td>1.311998</td>\n",
       "      <td>1.192376</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>0.502480</td>\n",
       "      <td>0.285432</td>\n",
       "      <td>-1.439179</td>\n",
       "      <td>-0.921630</td>\n",
       "      <td>1.478914</td>\n",
       "      <td>0.776199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>0.697109</td>\n",
       "      <td>1.224258</td>\n",
       "      <td>-1.439179</td>\n",
       "      <td>-0.647427</td>\n",
       "      <td>0.644336</td>\n",
       "      <td>-0.330215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id       age  current_house_years  current_job_years  experience  \\\n",
       "456  -1.576452 -0.888100            -0.002514          -0.373224    1.311998   \n",
       "920  -1.415761  1.634994            -0.002514          -0.099022    0.644336   \n",
       "1267 -1.295590  1.693671            -1.439179          -0.373224    1.311998   \n",
       "6459  0.502480  0.285432            -1.439179          -0.921630    1.478914   \n",
       "7021  0.697109  1.224258            -1.439179          -0.647427    0.644336   \n",
       "\n",
       "        income  risk_flag  \n",
       "456   1.240050        0.0  \n",
       "920  -0.997847        1.0  \n",
       "1267  1.192376        0.0  \n",
       "6459  0.776199        0.0  \n",
       "7021 -0.330215        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0956af97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>experience</th>\n",
       "      <th>income</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9673</th>\n",
       "      <td>1.631935</td>\n",
       "      <td>0.524360</td>\n",
       "      <td>-0.663697</td>\n",
       "      <td>-0.348132</td>\n",
       "      <td>-0.826505</td>\n",
       "      <td>0.211965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>1.601777</td>\n",
       "      <td>0.936084</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>-1.701153</td>\n",
       "      <td>-1.649964</td>\n",
       "      <td>0.616538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>-1.225128</td>\n",
       "      <td>0.171454</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>-0.348132</td>\n",
       "      <td>-0.826505</td>\n",
       "      <td>-1.119756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>-0.319340</td>\n",
       "      <td>1.406625</td>\n",
       "      <td>-0.663697</td>\n",
       "      <td>-0.348132</td>\n",
       "      <td>-0.826505</td>\n",
       "      <td>0.840230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>-0.874668</td>\n",
       "      <td>1.347808</td>\n",
       "      <td>0.045381</td>\n",
       "      <td>-0.889340</td>\n",
       "      <td>0.491028</td>\n",
       "      <td>-1.594957</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id       age  current_house_years  current_job_years  experience  \\\n",
       "9673  1.631935  0.524360            -0.663697          -0.348132   -0.826505   \n",
       "9586  1.601777  0.936084             0.045381          -1.701153   -1.649964   \n",
       "1431 -1.225128  0.171454             0.045381          -0.348132   -0.826505   \n",
       "4044 -0.319340  1.406625            -0.663697          -0.348132   -0.826505   \n",
       "2442 -0.874668  1.347808             0.045381          -0.889340    0.491028   \n",
       "\n",
       "        income  risk_flag  \n",
       "9673  0.211965        0.0  \n",
       "9586  0.616538        0.0  \n",
       "1431 -1.119756        0.0  \n",
       "4044  0.840230        1.0  \n",
       "2442 -1.594957        0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec43d9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8000, 2), dtype=float32, numpy=\n",
       "array([[-0.8880996 ,  1.3119982 ],\n",
       "       [ 1.634994  ,  0.6443359 ],\n",
       "       [ 1.6936706 ,  1.3119982 ],\n",
       "       ...,\n",
       "       [ 1.5763174 , -1.02482   ],\n",
       "       [-0.53604007, -0.02332645],\n",
       "       [-0.9467762 , -0.6909888 ]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "feature_columns.append(age)\n",
    "exp = tf.feature_column.numeric_column(\"experience\")\n",
    "feature_columns.append(exp)\n",
    "feature_layer = layers.DenseFeatures(feature_columns)\n",
    "feature_layer(dict(train_df_norm))\n",
    "##adding required features to the feature columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a563b6",
   "metadata": {},
   "source": [
    "## *Defining functions for the classification model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "010ed6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate, feature_layer, my_metrics):\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  model.add(feature_layer)\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                  activation=tf.sigmoid),)\n",
    "   \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),                                                   \n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=my_metrics)\n",
    "\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6395a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None, shuffle=True):\n",
    "\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name)) \n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=shuffle)\n",
    "  \n",
    "  epochs = history.epoch\n",
    "\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d25022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250dc371",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>current_house_years</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>experience</th>\n",
       "      <th>income</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.252332e-16</td>\n",
       "      <td>-2.486900e-17</td>\n",
       "      <td>-5.373479e-16</td>\n",
       "      <td>-9.370282e-17</td>\n",
       "      <td>1.167955e-16</td>\n",
       "      <td>-1.065814e-17</td>\n",
       "      <td>0.149750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.356849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.734372e+00</td>\n",
       "      <td>-1.709572e+00</td>\n",
       "      <td>-1.439179e+00</td>\n",
       "      <td>-1.744239e+00</td>\n",
       "      <td>-1.692482e+00</td>\n",
       "      <td>-1.746293e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.679769e-01</td>\n",
       "      <td>-8.880996e-01</td>\n",
       "      <td>-7.208464e-01</td>\n",
       "      <td>-6.474274e-01</td>\n",
       "      <td>-8.579044e-01</td>\n",
       "      <td>-8.622822e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.305134e-03</td>\n",
       "      <td>-7.950679e-03</td>\n",
       "      <td>-2.514163e-03</td>\n",
       "      <td>-9.902154e-02</td>\n",
       "      <td>-2.332645e-02</td>\n",
       "      <td>9.619795e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.675830e-01</td>\n",
       "      <td>8.721983e-01</td>\n",
       "      <td>7.158181e-01</td>\n",
       "      <td>7.235873e-01</td>\n",
       "      <td>8.112515e-01</td>\n",
       "      <td>8.608387e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.727744e+00</td>\n",
       "      <td>1.693671e+00</td>\n",
       "      <td>1.434150e+00</td>\n",
       "      <td>2.094602e+00</td>\n",
       "      <td>1.645829e+00</td>\n",
       "      <td>1.735447e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id           age  current_house_years  current_job_years  \\\n",
       "count  8.000000e+03  8.000000e+03         8.000000e+03       8.000000e+03   \n",
       "mean  -1.252332e-16 -2.486900e-17        -5.373479e-16      -9.370282e-17   \n",
       "std    1.000000e+00  1.000000e+00         1.000000e+00       1.000000e+00   \n",
       "min   -1.734372e+00 -1.709572e+00        -1.439179e+00      -1.744239e+00   \n",
       "25%   -8.679769e-01 -8.880996e-01        -7.208464e-01      -6.474274e-01   \n",
       "50%    4.305134e-03 -7.950679e-03        -2.514163e-03      -9.902154e-02   \n",
       "75%    8.675830e-01  8.721983e-01         7.158181e-01       7.235873e-01   \n",
       "max    1.727744e+00  1.693671e+00         1.434150e+00       2.094602e+00   \n",
       "\n",
       "         experience        income    risk_flag  \n",
       "count  8.000000e+03  8.000000e+03  8000.000000  \n",
       "mean   1.167955e-16 -1.065814e-17     0.149750  \n",
       "std    1.000000e+00  1.000000e+00     0.356849  \n",
       "min   -1.692482e+00 -1.746293e+00     0.000000  \n",
       "25%   -8.579044e-01 -8.622822e-01     0.000000  \n",
       "50%   -2.332645e-02  9.619795e-03     0.000000  \n",
       "75%    8.112515e-01  8.608387e-01     0.000000  \n",
       "max    1.645829e+00  1.735447e+00     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e073b3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Id': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'current_house_years': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'current_job_years': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'experience': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>, 'income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Id': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'current_house_years': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'current_job_years': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'experience': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>, 'income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.8099 - accuracy: 0.4389\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 0.7662 - accuracy: 0.4511\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 701us/step - loss: 0.7248 - accuracy: 0.4590\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 598us/step - loss: 0.6860 - accuracy: 0.4750\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 910us/step - loss: 0.6501 - accuracy: 0.4869\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 717us/step - loss: 0.6171 - accuracy: 0.5136\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 675us/step - loss: 0.5874 - accuracy: 0.5391\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 719us/step - loss: 0.5602 - accuracy: 0.5785\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 664us/step - loss: 0.5362 - accuracy: 0.6130\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.5153 - accuracy: 0.6734\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.4971 - accuracy: 0.7517\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.4816 - accuracy: 0.8374\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 686us/step - loss: 0.4691 - accuracy: 0.8503\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 584us/step - loss: 0.4586 - accuracy: 0.8503\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 613us/step - loss: 0.4501 - accuracy: 0.8503\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.4432 - accuracy: 0.8503\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 721us/step - loss: 0.4375 - accuracy: 0.8503\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 651us/step - loss: 0.4330 - accuracy: 0.8503\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 699us/step - loss: 0.4295 - accuracy: 0.8503\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 572us/step - loss: 0.4269 - accuracy: 0.8503\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.4252 - accuracy: 0.8503\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.4241 - accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 674us/step - loss: 0.4234 - accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 709us/step - loss: 0.4229 - accuracy: 0.8503\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 654us/step - loss: 0.4226 - accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 683us/step - loss: 0.4224 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 679us/step - loss: 0.4223 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 685us/step - loss: 0.4223 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 661us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 684us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 658us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 668us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 658us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 691us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 689us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 686us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 625us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 691us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 681us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 671us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 681us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 645us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 686us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 560us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 626us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 641us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 707us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 663us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 683us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 672us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 669us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 588us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 674us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 676us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 671us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 653us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 674us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 654us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 558us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 547us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 596us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 575us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 678us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 658us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 629us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 732us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 689us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.4222 - accuracy: 0.8503\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 683us/step - loss: 0.4222 - accuracy: 0.8503\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "label_name = \"risk_flag\"\n",
    "classification_threshold = 0.4\n",
    "\n",
    "METRICS = [\n",
    "           tf.keras.metrics.BinaryAccuracy(name='accuracy', \n",
    "                                           threshold=classification_threshold),\n",
    "          ]\n",
    "\n",
    "my_model = create_model(learning_rate, feature_layer, METRICS)\n",
    "\n",
    "epochs, hist = train_model(my_model, train_df_norm, epochs, \n",
    "                           label_name, batch_size)\n",
    "\n",
    "list_of_metrics_to_plot = ['accuracy'] \n",
    "\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6e904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'Id': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'current_house_years': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'current_job_years': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'experience': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>, 'income': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "20/20 [==============================] - 0s 630us/step - loss: 0.4540 - accuracy: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45402950048446655, 0.8314999938011169]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "label = np.array(features.pop(label_name))\n",
    "\n",
    "my_model.evaluate(x = features, y = label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd83cf3",
   "metadata": {},
   "source": [
    "# *Result Accuracy on the test data : 83%*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
